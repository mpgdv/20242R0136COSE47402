{"cells":[{"cell_type":"markdown","source":["# 7.4 Multiple Input and Multiple Output Channels"],"metadata":{"id":"YVEXfr1vWVYh"}},{"cell_type":"code","source":["import torch\n","from d2l import torch as d2l"],"metadata":{"id":"zYpEAKdTE54W","executionInfo":{"status":"ok","timestamp":1728536791741,"user_tz":-540,"elapsed":7509,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### 7.4.1 Multiple Input Channels"],"metadata":{"id":"yOpDy6epFyVD"}},{"cell_type":"code","source":["#Performing a cross-correlation operation per channel and then adding up the results\n","def corr2d_multi_in(X,K):\n","  #Iterate through the 0th dimension (channel) of K first, then add them up\n","  return sum(d2l.corr2d(x,k) for x,k in zip(X,K))"],"metadata":{"id":"LQt8Rs0mF0-E","executionInfo":{"status":"ok","timestamp":1728536800170,"user_tz":-540,"elapsed":380,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n","               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n","K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n","\n","corr2d_multi_in(X, K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"sHc1ycaIJH8k","executionInfo":{"status":"ok","timestamp":1728536804118,"user_tz":-540,"elapsed":410,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"f78a8573-4bb9-4156-d40c-7aeafe3237b9"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 56.,  72.],\n","        [104., 120.]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### 7.4.2 Multiple Output Channels"],"metadata":{"id":"FCi6GBmsJoAf"}},{"cell_type":"code","source":["def corr2d_multi_in_out(X,K):\n","  #Iterate through the 0th dimension of K, and each time, perform cross-correlation\n","  #operations with input X. All of the results are stacked together\n","  return torch.stack([corr2d_multi_in(X,k) for k in K],0)"],"metadata":{"id":"4OeLMDrnP471","executionInfo":{"status":"ok","timestamp":1728536806643,"user_tz":-540,"elapsed":433,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["K = torch.stack((K, K+1, K+2),0)\n","K.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"PNUQohDNQOqJ","executionInfo":{"status":"ok","timestamp":1728536817327,"user_tz":-540,"elapsed":407,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"080d9141-d116-412f-ef42-0f44404885d8"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 2, 2, 2])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Now the output contains three channels\n","corr2d_multi_in_out(X, K)"],"metadata":{"id":"R7obKLxnQ4oF","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1728536821304,"user_tz":-540,"elapsed":412,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"aecafd57-9711-4416-f72c-467e099f1826"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 56.,  72.],\n","         [104., 120.]],\n","\n","        [[ 76., 100.],\n","         [148., 172.]],\n","\n","        [[ 96., 128.],\n","         [192., 224.]]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### 7.4.3 1x1 Convolutional Layer"],"metadata":{"id":"nbWaaCTgRAma"}},{"cell_type":"code","source":["#We need to make some adjustments to the data shape before and after the matrix multiplication\n","def corr2d_multi_in_out_1x1(X,K):\n","  c_i, h, w = X.shape\n","  c_o = K.shape[0]\n","  X = X.reshape((c_i, h * w))\n","  K = K.reshape((c_o, c_i))\n","  #Matrix multiplication in the fully connected layer\n","  Y = torch.matmul(K, X)\n","  return Y.reshape((c_o, h, w))"],"metadata":{"id":"hbotTL4nSmYE","executionInfo":{"status":"ok","timestamp":1728536824556,"user_tz":-540,"elapsed":396,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["X = torch.normal(0, 1, (3, 3, 3))\n","K = torch.normal(0, 1, (2, 3, 1, 1))\n","Y1 = corr2d_multi_in_out_1x1(X,K)\n","Y2 = corr2d_multi_in_out(X, K)\n","assert float(torch.abs(Y1 -Y2).sum()) < 1e-6"],"metadata":{"id":"6UNUILIPTsNH","executionInfo":{"status":"ok","timestamp":1728536827368,"user_tz":-540,"elapsed":396,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Discussions"],"metadata":{"id":"6xjLvKb_qYLm"}},{"cell_type":"markdown","source":["- When we add channels into the mix, our inputs and hidden representations both become three-dimensional tensors.\n","- Channel dimension\n","\n","7.4.1 Multiple Input Channels\n","- When the input data contains multiple channels, we need to construct a convolution kernel with the same number of input channels as the input data, so that it can perform cross-correlation with the input data.\n","- Since the input and convolution kernel each have $c_i$  channels, we can perform a cross-correlation operation on the two-dimensional tensor of the input and the two-dimensional tensor of the convolution kernel for each channel, adding the $c_i$ results together (summing over the channels) to yield a two-dimensional tensor. This is the result of a two-dimensional cross-correlation between a multi-channel input and a multi-input-channel convolution kernel.\n","\n","7.4.2. Multiple Output Channels\n","- It's essential to have multiple channels at each layer.\n","- In the most popular neural network, we actually increase the channel dimension as we go deeper in the neural network, typically downsampling to trade off spatial resolution for greater *channel depth*\n","- Denote by $c_i$ and $c_o$ the number of input and output channels, respectively, and by $k_h$ and $k_w$ the height and width of the kernel. To get an output with multiple channels, we can create a kernel tensor of shape $c_i \\times k_h \\times k_w$ for every output channel. We concatenate them on the output channel dimension, so that the shape of the convolution kernel is $c_o \\times c_i \\times k_h \\times k_w$. In cross-correlation operations, the result on each output channel is calculated from the convolution kernel corresponding to that output channel and takes input from all channels in the input tensor.\n","\n","7.4.3 1x1 Convolutional Layer\n","- They are popular operations that are sometimes inlcuded in the designs of complex deep networks.\n","- The 1x1 convolution loses the ability of larger convolutional layers to recognize patterns consisting of interactions among adjacents elements in the height and width dimensions. The only computation of the 1x1 convolution occurs on the channel dimension"],"metadata":{"id":"U4okhUI_D9VS"}},{"cell_type":"markdown","source":["- Channels allow the CNN to reason with multiple features, such as edge and shape detectors at the same time\n","- Channels offer a pratical trade-off between the drastic parameter reduction arising from the translation invariance and locality, and the need for expressive and diverse models in computer vision.\n","- Given an image of size ($h \\times w$), the cost for computing a $k \\times k$ convolutions is $O(h \\cdot w \\cdot k^2)$. For $c_i$ and $c_o$ input and output channels respectively this increasses to $O(h \\cdot w \\cdot k^2 \\cdot c_i \\cdot c_o)$"],"metadata":{"id":"o8CQ6-RsUPNl"}},{"cell_type":"markdown","source":["### Exercises"],"metadata":{"id":"QSroNYD7cNrL"}},{"cell_type":"markdown","source":["1. Assume that we have two convolution kernels of size $k_1$ and $k_2$, respectively (with no nonlinearity in between).\n","\n","Prove that the result of the operation can be expressed by a single convolution.\n","\n","$h_1$ and $h_2$ being two convolution kernels of sizes $k_1$ and $k_2$.\n","The first convolution is:\n","  $$y_1 = h_1 * x$$\n","the second convolution:\n","$$y_2 = h_2 * y_1 = h_2*(h_1*x)$$\n","Because convolutions are associative, the result of two consecutive convolutions can be replaced by a single convolution with a kernel that is the convolution of $h_1$ and $h_2$:\n","  $$h_{eq} = h_2*h_1$$\n"],"metadata":{"id":"hDQd3rozyKeT"}},{"cell_type":"markdown","source":["What is the dimensionality of the equivalent single convolution?\n","  $$k_{eq} = k_1 + k_2 - 1$$"],"metadata":{"id":"AgwnvM63z9d4"}},{"cell_type":"markdown","source":["2. Are the variables Y1 and Y2 in the final example of this section exactly the same? Why?"],"metadata":{"id":"qLP7Ace90zJq"}},{"cell_type":"markdown","source":["In both functions, corr2d_multi_in_ou_1x1 and corr2d_multi_in_out, the mathematical operation that is performed is identical for a 1x1  convolution. The only difference is how the computation is tructured. corr2d_multi_in_ou_1x1 uses matrix multiplication to achieve the result in one step, while corr2d_mult_in_out uses iterative convolutions across the input channels and outputs"],"metadata":{"id":"olKIYZG-1LyV"}},{"cell_type":"code","source":["assert float(torch.abs(Y1 -Y2).sum()) < 1e-6"],"metadata":{"id":"UKg4N3lh00HK","executionInfo":{"status":"ok","timestamp":1728537154157,"user_tz":-540,"elapsed":414,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}}},"execution_count":13,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZ0tOGRFb65pEuOQJ4eKRU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}