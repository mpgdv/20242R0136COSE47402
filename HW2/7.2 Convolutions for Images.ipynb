{"cells":[{"cell_type":"markdown","source":["# 7.2 Convolutions for Images"],"metadata":{"id":"YVEXfr1vWVYh"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from d2l import torch as d2l"],"metadata":{"id":"4P16S-Rv9yIP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 7.2.1 The Cross-Correlation Operation"],"metadata":{"id":"DvDr7AZ7-I2Y"}},{"cell_type":"code","source":["def corr2d(X,K):#Input tensor X, kernel tensor K\n","  \"\"\"Compute 2D cross-correlation\"\"\"\n","  h, w = K.shape\n","  Y = torch.zeros((X.shape[0] - h +1, X.shape[1] - w + 1))\n","  for i in range(Y.shape[0]):\n","    for j in range(Y.shape[1]):\n","      Y[i,j] = (X[i:i+h, j:j + w]*K).sum()\n","  return Y"],"metadata":{"id":"BAcgI2vEAB3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n","corr2d(X, K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2YmPNZFAnUj","executionInfo":{"status":"ok","timestamp":1727768208429,"user_tz":-540,"elapsed":734,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"e8959f16-49f4-4fa5-d739-4f668bd7a907"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[19., 25.],\n","        [37., 43.]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### 7.2.2 Convolutional Layers"],"metadata":{"id":"QlADHDbVC7Ft"}},{"cell_type":"code","source":["class Conv2D(nn.Module):\n","  def __init__(self, kernel_size):\n","    super().__init__()\n","    self.weight = nn.Parameter(torch.rand(kernel_size))\n","    self.bias = nn.Parameter(torch.zeros(1))\n","\n","  def forward(self, x):\n","    return corr2d(x, self.weight) + self.bias"],"metadata":{"id":"oC__5JBvC-UR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 7.2.3 Object Edge Detection in Images"],"metadata":{"id":"7wgCcvh4DXgX"}},{"cell_type":"code","source":["X = torch.ones((6,8))\n","X[:,2:6] = 0\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCdznwBXDdIW","executionInfo":{"status":"ok","timestamp":1727768971839,"user_tz":-540,"elapsed":489,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"dea1e143-26ce-49b4-9ecb-cde8bc55f4b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["K = torch.tensor([[1.0,-1.0]])"],"metadata":{"id":"d07GuWPcDoC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y = corr2d(X,K)\n","Y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PnAuu-3DrxW","executionInfo":{"status":"ok","timestamp":1727769030717,"user_tz":-540,"elapsed":458,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"c2123ea7-67f6-4ffe-b002-4a89b7f7d25d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["corr2d(X.t(),K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auCmlbMmD0po","executionInfo":{"status":"ok","timestamp":1727769064732,"user_tz":-540,"elapsed":12,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"555e992b-457c-4088-f888-2c2849d9d025"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### 7.2.4 Learning a Kernel"],"metadata":{"id":"zJLyx287EFX4"}},{"cell_type":"code","source":["# Construct a two-dimensional convolutional layer with 1 output channel and a\n","# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n","conv2d = nn.LazyConv2d(1,kernel_size=(1,2),bias=False)\n","\n","# The two-dimensional convolutional layer uses four-dimensional input and\n","# output in the format of (example, channel, height, width), where the batch\n","# size (number of examples in the batch) and the number of channels are both 1\n","X = X.reshape((1,1,6,8))\n","Y = Y.reshape((1,1,6,7))\n","lr = 3e-2 #Learning rate\n","\n","for i in range(10):\n","  Y_hat = conv2d(X)\n","  l = (Y_hat - Y)**2\n","  conv2d.zero_grad()\n","  l.sum().backward()\n","  #Update the kernel\n","  conv2d.weight.data[:] -= lr * conv2d.weight.grad\n","  if(i+1) % 2 == 0:\n","    print(f'epoch {i+1}, loss {l.sum():.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmwMyTT-EHvc","executionInfo":{"status":"ok","timestamp":1727769536701,"user_tz":-540,"elapsed":562,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"2c3841a0-a4bb-432f-fff7-439cca3dd574"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 2, loss 8.644\n","epoch 4, loss 2.690\n","epoch 6, loss 0.959\n","epoch 8, loss 0.369\n","epoch 10, loss 0.147\n"]}]},{"cell_type":"code","source":["conv2d.weight.data.reshape((1,2))"],"metadata":{"id":"iyrjhSB9F_fc","executionInfo":{"status":"ok","timestamp":1727769618584,"user_tz":-540,"elapsed":488,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"e002a9a3-47dc-461d-a0ef-f35b281af4e0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.9510, -1.0295]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## Discussions"],"metadata":{"id":"6xjLvKb_qYLm"}},{"cell_type":"markdown","source":["7.2.1 The Cross-Correlation Operation\n","- Convolutional layers are more accurately described as cross-correlations. In such a layer, an input tensor and a kernel tensor are combined to produce an output tensor through a cross-correlation operation.\n","- The shape of the kernel window (or convolution window) is given by the height and width of the kernel.\n","- In the two-dimensional cross-correlation operation, we begin with the convolution window positioned at the upper-left corner of the input tensor and slide it across the input tensor, both from left to right and top to bottom. When the convolution window slides to a certain position, the input subtensor contained in that window and the kernel tensor are multiplied elementwise and the resulting tensor is summed up yielding a single scalar value.\n","- Note that along each axis, the output size is slightly smaller than the input size.\n","- The output size is given by the input size $n_h$ x $n_w$ minus the size of the convolution kernel $k_h$ x $k_w$ via\n","$(n_h - k_h+1)$x$(n_w - k_w +1)$\n","\n","7.2.2 Convolutional Layers\n","- A convolutional layer cross-correlates the input and kernel and adds a scalar bias to produce an output.\n","- The two parameters of a convolutional layer are the kernel and the scalar bias.\n","\n","7.2.3 Object Edge Detection in Images\n","- When we perform the cross-correlation operation with the input, if the horizontally adjacent elements are the same, the output is 0. Otherwise, the output is nonzero.\n","\n","7.2.5 Cross-Correlation and Convolution\n","- In order to obtain the output of the strict convolution operation, we only need to flip the two-dimensional kernel tensor both horizontally and vertically and then perform the cross-correlation operation with the input tensor.\n","\n","7.2.6 Feature Map and Receptive Field\n","- The convolutional layer output is sometimes called a feature map, as it can be regarded as the learned representations (features) in the spatial dimensions to the subsequent layer.\n","- In CNNs, for any element $x$\n"," of some layer, its receptive field refers to all the elements (from all the previous layers) that may affect the calculation of $x$ during the forward propagation.\n"," - Receptive fields detive their name from neurophysiology\n","\n"," - The core computation required for a convolutional layer is a cross-correlation operation.\n"," - Convolutions can be used for many purposes, for example detecting edges and lines, blurring images, or sharpening them."],"metadata":{"id":"9BV7PMtw-VVN"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLku9MDy55ofrXdoUaLxgn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}