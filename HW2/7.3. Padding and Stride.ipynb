{"cells":[{"cell_type":"markdown","source":["# 7.3. Padding and Stride"],"metadata":{"id":"YVEXfr1vWVYh"}},{"cell_type":"code","source":["import torch\n","from torch import nn"],"metadata":{"id":"1pVh8cycfLTI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 7.3.1 Padding"],"metadata":{"id":"67q7S9v-z2ih"}},{"cell_type":"code","source":["# We define a helper function to calculate convolutions. It initializes the\n","# convolutional layer weights and performs corresponding dimensionality\n","# elevations and reductions on the input and output\n","def comp_conv2d(conv2d, X):\n","  # (1, 1) indicates that batch size and the number of channels are both 1\n","  X = X.reshape((1,1) + X.shape)\n","  Y = conv2d(X)\n","  # Strip the first two dimensions: examples and channels\n","  return Y.reshape(Y.shape[2:])\n","# 1 row and column is padded on either side, so a total of 2 rows or columns are added\n","conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n","X = torch.rand(size=(8,8))\n","comp_conv2d(conv2d, X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QeHheDe9z59S","executionInfo":{"status":"ok","timestamp":1728050249292,"user_tz":-540,"elapsed":438,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"d9cab23d-7269-4184-9469-e9f3ccbb15fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 8])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["When the height and width of the convolution kernel are different, we can make the output and input have the same height and width by setting different padding numbers for height and width."],"metadata":{"id":"8RcI7J3n0m8o"}},{"cell_type":"code","source":["# We use a convolution kernel with height 5 and width 3. The padding on either\n","# side of the height and width are 2 and 1, respectively\n","conv2d = nn.LazyConv2d(1, kernel_size=(5,3), padding=(2,1))\n","comp_conv2d(conv2d, X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xyp9NFWc0mOk","executionInfo":{"status":"ok","timestamp":1728050329010,"user_tz":-540,"elapsed":433,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"73355a15-447e-47e8-9a0b-580633021e2a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 8])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### 7.3.2 Stride"],"metadata":{"id":"n7WWl8t706LH"}},{"cell_type":"code","source":["conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n","comp_conv2d(conv2d, X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmt9azUL24wl","executionInfo":{"status":"ok","timestamp":1728050897456,"user_tz":-540,"elapsed":406,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"5cc4e083-3279-4375-db17-928f39eae16b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 4])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["conv2d = nn.LazyConv2d(1, kernel_size=(3,5), padding=(0,1), stride=(3,4))\n","comp_conv2d(conv2d, X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66wxqDeZ3DjQ","executionInfo":{"status":"ok","timestamp":1728050947281,"user_tz":-540,"elapsed":400,"user":{"displayName":"María Paredes Gutiérrez de Velasco","userId":"08236741522571502209"}},"outputId":"53fa7621-2f2c-4104-dcae-58f73077e28c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 2])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## Discussions"],"metadata":{"id":"6xjLvKb_qYLm"}},{"cell_type":"markdown","source":["- Assuming that the input shape is $n_h \\times n_w$ and the convolution kernel shape is $k_h \\times k_w$ the output shape will be $(n_h - k_h +1)\\times (n_w-k_w + 1)$: we can only shift the convolution kernel so far until it runs out of pixels to apply the convolution to.\n","- One issue when applying convolutional layers is that we tend to lose pixels on the perimeter of our image.\n","\n","7.3.1 Padding\n","- A straightforward solution to the problem of losing pixels is to add extra pixels of filler around the boundary of our input image, thus increasing the effective size of the image. Typically, we set the values of the extra pixels to zero.\n","- In general, if we add a total of $p_h$ rows of padding (roughly half on top and half on bottom) and a total of $p_w$ columns of padding (roughly half on the left and half on the right), the output shape will be $$ (n_h - k_h + p_h +1)\\times(n_w-k_w+p_w+1)$$\n","  - In many cases, we will want to set $p_h = k_h-1$ and $p_w = k_w-1$ to give the input and output the same height and width.\n","  - Assuming that $k_h$ is odd here, we will pad $p_h/2$rows on both sides of the height. If $k_h$ is even, one possibility is to pad $\\lceil p_h /2 \\rceil$ rows on the top of the input and $\\lfloor p_h /2 \\rfloor$ rows on the bottom. We will pad both sides of the width in the same way.\n","- CNNs commonly use convolution kernels with odd height and width values, such as 1, 3, 5, or 7.\n","\n","7.3.2 Stride\n","- Sometimes we move our window more than one element at a time, skipping the intermediate locations. This is useful if the convolution kernel is large since it captures a large area of the underlying image.\n","- We refer to the number of rows and columns traversed per slide as stride.\n","- In general, when the strinde for height is $s_h$ and the stride for the width is $s_w$, the output shape is\n","$$\n","(n_h/s_h)\\times(n_w/s_w)\n","$$\n","\n","\n","- Padding can increase the height and width of the output. Often used to give the output the same height and width as the input to avoid undesirable shrinkage of the output. It ensures that all pixels are used equally frequently.\n","- Typically we pick symmetric padding on both sides of the input height and width. In which case we simply state that we choose padding $p$"],"metadata":{"id":"qeM3UHRnmNXS"}},{"cell_type":"markdown","source":["### Exercises"],"metadata":{"id":"QSroNYD7cNrL"}},{"cell_type":"markdown","source":["1. For audio signals, what does a stride of 2 correspond to?\n","\n","With stride 2, the filter moves two samples at a time.\n","\n","2. What are the computational benefits of a stride larger than 1?\n","\n","It reduces computational complexity. Reduces the number of computations needed for a given layer and fewer output values are computed.\n","Also, since fewer output activations are produced, memory usage is also reduced."],"metadata":{"id":"KfoM462is3oF"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSAKEk+5SRC9PQUQYE3yLV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}